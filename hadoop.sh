#!/bin/bash

#=============================================================================
# Hadoop é›†ç¾¤è‡ªåŠ¨éƒ¨ç½²è„šæœ¬
# é€‚ç”¨äº: Ubuntu 24.04 + Hadoop 3.4.2 + OpenJDK 17
# ä½¿ç”¨æ–¹æ³•: bash hadoop_deploy.sh
#=============================================================================

set -e # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# å…¨å±€å˜é‡
HADOOP_VERSION="3.4.2"
HADOOP_USER="hadoop"
HADOOP_PASSWORD=""
CURRENT_USER=""
CURRENT_USER_PASSWORD=""
MASTER_IP=""
MASTER_HOSTNAME="hadoop01"
SLAVE_COUNT=0
declare -a SLAVE_IPS
declare -a SLAVE_HOSTNAMES

# æ­¥éª¤æ§åˆ¶
START_STEP=1

#=============================================================================
# å·¥å…·å‡½æ•°
#=============================================================================

print_info() {
  echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
  echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
  echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
  echo -e "${RED}[ERROR]${NC} $1"
}

print_step() {
  echo -e "\n${GREEN}========================================${NC}"
  echo -e "${GREEN}$1${NC}"
  echo -e "${GREEN}========================================${NC}\n"
}

print_progress() {
  echo -e "${CYAN}[è¿›åº¦]${NC} $1"
}

# åœ¨è¿œç¨‹èŠ‚ç‚¹æ‰§è¡Œå‘½ä»¤
exec_remote() {
  local host="$1"
  local cmd="$2"
  local user="${3:-$CURRENT_USER}"
  local pwd="${4:-$CURRENT_USER_PASSWORD}"

  # åˆ¤æ–­å‘½ä»¤æ˜¯å¦åŒ…å« sudo
  if [[ "$cmd" == *"sudo"* ]]; then
    sshpass -p "$pwd" ssh -o StrictHostKeyChecking=no "${user}@${host}" \
      "echo '$pwd' | sudo -S -p '' bash -c \"$cmd\""
  else
    # é sudoï¼Œç›´æ¥æ‰§è¡Œ
    sshpass -p "$pwd" ssh -o StrictHostKeyChecking=no "${user}@${host}" \
      "bash -c \"$cmd\""
  fi
}

# å‘è¿œç¨‹èŠ‚ç‚¹å¤åˆ¶æ–‡ä»¶
copy_to_remote() {
  local host=$1
  local src=$2
  local dest=$3
  local pwd=$4
  local user=$5
  sshpass -p "$pwd" rsync -avz --progress -e "ssh -o StrictHostKeyChecking=no" "$src" ${user}@${host}:"$dest"
}

# è¯¢é—®ç”¨æˆ·é€‰æ‹©
ask_user_choice() {
  local prompt="$1"
  echo -e "${YELLOW}$prompt${NC}"
  echo "  1) é‡æ–°æ‰§è¡Œ (reinstall)"
  echo "  2) è·³è¿‡æ­¤æ­¥éª¤ (skip)"
  echo "  3) é€€å‡ºè„šæœ¬ (exit)"
}

# æ˜¾ç¤ºè¿›åº¦æ¡
show_progress() {
  local current=$1
  local total=$2
  local task=$3
  local percent=$((current * 100 / total))
  local completed=$((current * 50 / total))
  local remaining=$((50 - completed))

  printf "\r${CYAN}[%3d%%]${NC} [" $percent
  printf "%${completed}s" | tr ' ' '='
  printf "%${remaining}s" | tr ' ' '-'
  printf "] %s" "$task"
}

#=============================================================================
# æ¸…ç†å’Œé‡ç½®ç¯å¢ƒå˜é‡
#=============================================================================

reset_environment_variables() {
  print_step "æ¸…ç†å¹¶é‡ç½®ç¯å¢ƒå˜é‡"

  print_info "è¿™å°†æ¸…ç†æ‰€æœ‰èŠ‚ç‚¹çš„ .bashrc ä¸­çš„ Java å’Œ Hadoop ç¯å¢ƒå˜é‡"
  echo -n "ç¡®è®¤è¦ç»§ç»­å—? (yes/no): "
  read confirm
  if [ "$confirm" != "yes" ]; then
    print_warning "æ“ä½œå·²å–æ¶ˆ"
    return 0
  fi

  local total_nodes=$((SLAVE_COUNT + 1))
  local current=0

  # æ¸…ç† Master èŠ‚ç‚¹
  current=$((current + 1))
  show_progress $current $total_nodes "æ¸…ç† Master èŠ‚ç‚¹ç¯å¢ƒå˜é‡"
  exec_remote "$MASTER_IP" "
# å¤‡ä»½åŸå§‹ .bashrc
cp ~/.bashrc ~/.bashrc.bak.\$(date +%Y%m%d_%H%M%S)

# åˆ é™¤ Java å’Œ Hadoop ç›¸å…³çš„ç¯å¢ƒå˜é‡
sed -i '/# Java Environment/d' ~/.bashrc
sed -i '/# Hadoop Environment/d' ~/.bashrc
sed -i '/JAVA_HOME.*jdk-17.0.12-oracle-x64/d' ~/.bashrc
sed -i '/HADOOP_HOME.*\/usr\/local\/hadoop/d' ~/.bashrc
sed -i '/HADOOP_CONF_DIR/d' ~/.bashrc
sed -i '/PATH.*JAVA_HOME/d' ~/.bashrc
sed -i '/PATH.*HADOOP_HOME/d' ~/.bashrc

# åˆ é™¤ç©ºè¡Œï¼ˆå¦‚æœæœ‰å¤šä¸ªè¿ç»­çš„ï¼‰
sed -i '/^$/N;/^\n$/d' ~/.bashrc

# é‡æ–°æ·»åŠ æ­£ç¡®çš„ç¯å¢ƒå˜é‡
echo '' >> ~/.bashrc
echo '# Java Environment' >> ~/.bashrc
echo 'export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64' >> ~/.bashrc
echo 'export PATH=\$PATH:\$JAVA_HOME/bin' >> ~/.bashrc
echo '' >> ~/.bashrc
echo '# Hadoop Environment' >> ~/.bashrc
echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
echo 'export HADOOP_CONF_DIR=\$HADOOP_HOME/etc/hadoop' >> ~/.bashrc
echo 'export PATH=\$PATH:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin' >> ~/.bashrc
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  # æ¸…ç†æ‰€æœ‰ Slave èŠ‚ç‚¹
  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    current=$((current + 1))
    show_progress $current $total_nodes "æ¸…ç† ${SLAVE_HOSTNAMES[$i]} ç¯å¢ƒå˜é‡"
    exec_remote "${SLAVE_IPS[$i]}" "
# å¤‡ä»½åŸå§‹ .bashrc
cp ~/.bashrc ~/.bashrc.bak.\$(date +%Y%m%d_%H%M%S)

# åˆ é™¤ Java å’Œ Hadoop ç›¸å…³çš„ç¯å¢ƒå˜é‡
sed -i '/# Java Environment/d' ~/.bashrc
sed -i '/# Hadoop Environment/d' ~/.bashrc
sed -i '/JAVA_HOME.*jdk-17.0.12-oracle-x64/d' ~/.bashrc
sed -i '/HADOOP_HOME.*\/usr\/local\/hadoop/d' ~/.bashrc
sed -i '/HADOOP_CONF_DIR/d' ~/.bashrc
sed -i '/PATH.*JAVA_HOME/d' ~/.bashrc
sed -i '/PATH.*HADOOP_HOME/d' ~/.bashrc

# åˆ é™¤ç©ºè¡Œï¼ˆå¦‚æœæœ‰å¤šä¸ªè¿ç»­çš„ï¼‰
sed -i '/^$/N;/^\n$/d' ~/.bashrc

# é‡æ–°æ·»åŠ æ­£ç¡®çš„ç¯å¢ƒå˜é‡
echo '' >> ~/.bashrc
echo '# Java Environment' >> ~/.bashrc
echo 'export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64' >> ~/.bashrc
echo 'export PATH=\$PATH:\$JAVA_HOME/bin' >> ~/.bashrc
echo '' >> ~/.bashrc
echo '# Hadoop Environment' >> ~/.bashrc
echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
echo 'export HADOOP_CONF_DIR=\$HADOOP_HOME/etc/hadoop' >> ~/.bashrc
echo 'export PATH=\$PATH:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbin' >> ~/.bashrc
" "$HADOOP_USER" "$HADOOP_PASSWORD"
    echo ""
  done

  print_success "ç¯å¢ƒå˜é‡å·²é‡ç½®å®Œæˆ"
  print_info "åŸå§‹ .bashrc å·²å¤‡ä»½ä¸º .bashrc.bak.<timestamp>"
  print_warning "è¯·åœ¨æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œ 'source ~/.bashrc' æˆ–é‡æ–°ç™»å½•ä»¥ä½¿ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ"
}

#=============================================================================
# åœæ­¢é›†ç¾¤
#=============================================================================

stop_cluster() {
  print_step "åœæ­¢ Hadoop é›†ç¾¤"

  # æ£€æŸ¥MasterèŠ‚ç‚¹è¿æ¥æ€§
  print_progress "æ£€æŸ¥ Master èŠ‚ç‚¹è¿æ¥..."
  if ! sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 ${HADOOP_USER}@${MASTER_IP} "echo ok" &>/dev/null; then
    print_error "æ— æ³•è¿æ¥åˆ° Master èŠ‚ç‚¹ $MASTER_IP"
    exit 1
  fi
  echo ""

  print_info "åœæ­¢ JobHistoryServer..."
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
source ~/.bashrc && mapred --daemon stop historyserver
" "$HADOOP_USER" "$HADOOP_PASSWORD" 2>/dev/null || true

  sleep 2

  print_info "åœæ­¢ YARN..."
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
source ~/.bashrc && stop-yarn.sh
" "$HADOOP_USER" "$HADOOP_PASSWORD" 2>/dev/null || true

  sleep 3

  print_info "åœæ­¢ HDFS..."
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
source ~/.bashrc && stop-dfs.sh
" "$HADOOP_USER" "$HADOOP_PASSWORD" 2>/dev/null || true

  sleep 2

  print_info "æ£€æŸ¥æ®‹ç•™è¿›ç¨‹..."
  exec_remote "$MASTER_IP" "source ~/.bashrc && jps" "$HADOOP_USER" "$HADOOP_PASSWORD"

  print_success "é›†ç¾¤å·²åœæ­¢"

  echo -e "\n${YELLOW}å¦‚éœ€å®Œå…¨æ¸…ç†ç¯å¢ƒï¼Œå¯ä»¥æ‰‹åŠ¨æ‰§è¡Œ:${NC}"
  echo -e "  ${CYAN}ssh $HADOOP_USER@$MASTER_IP${NC}"
  echo -e "  ${CYAN}rm -rf /usr/local/hadoop/tmp/dfs/*${NC}"
  echo -e "  ${CYAN}rm -rf /usr/local/hadoop/logs/*${NC}"
}

#=============================================================================
# ç”¨æˆ·è¾“å…¥æ”¶é›†
#=============================================================================

collect_cluster_info() {
  print_step "æ­¥éª¤ 1: æ”¶é›†é›†ç¾¤ä¿¡æ¯"

  # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
  CURRENT_USER=$(whoami)
  print_info "å½“å‰ç”¨æˆ·: $CURRENT_USER"

  # è·å–å½“å‰ç”¨æˆ·å¯†ç 
  echo -n "è¯·è¾“å…¥å½“å‰ç”¨æˆ·($CURRENT_USER)åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„å¯†ç : "
  read -s CURRENT_USER_PASSWORD
  echo ""

  # è·å–MasterèŠ‚ç‚¹IP
  echo -n "è¯·è¾“å…¥MasterèŠ‚ç‚¹çš„IPåœ°å€: "
  read MASTER_IP

  # è·å–SlaveèŠ‚ç‚¹æ•°é‡
  echo -n "è¯·è¾“å…¥SlaveèŠ‚ç‚¹æ•°é‡ (å»ºè®®2-10ä¸ª): "
  read SLAVE_COUNT

  if [ "$SLAVE_COUNT" -lt 1 ]; then
    print_error "è‡³å°‘éœ€è¦1ä¸ªSlaveèŠ‚ç‚¹"
    exit 1
  fi

  # è·å–æ¯ä¸ªSlaveèŠ‚ç‚¹çš„IP
  for i in $(seq 1 $SLAVE_COUNT); do
    local num=$(printf "%02d" $((i + 1)))
    echo -n "è¯·è¾“å…¥SlaveèŠ‚ç‚¹ $i çš„IPåœ°å€: "
    read slave_ip
    SLAVE_IPS+=("$slave_ip")
    SLAVE_HOSTNAMES+=("hadoop${num}")
  done

  # è·å–hadoopç”¨æˆ·å¯†ç 
  echo -n "è¯·è¾“å…¥è¦ä¸ºhadoopç”¨æˆ·è®¾ç½®çš„å¯†ç  (æ‰€æœ‰èŠ‚ç‚¹ä½¿ç”¨ç›¸åŒå¯†ç ): "
  read -s HADOOP_PASSWORD
  echo ""

  # ç¡®è®¤ä¿¡æ¯
  echo -e "\n${YELLOW}=== é›†ç¾¤é…ç½®ç¡®è®¤ ===${NC}"
  echo "å½“å‰æ“ä½œç”¨æˆ·: $CURRENT_USER"
  echo "MasterèŠ‚ç‚¹: $MASTER_HOSTNAME ($MASTER_IP)"
  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    echo "SlaveèŠ‚ç‚¹ $((i + 1)): ${SLAVE_HOSTNAMES[$i]} (${SLAVE_IPS[$i]})"
  done
  echo ""
  echo -n "ç¡®è®¤ä»¥ä¸Šä¿¡æ¯æ­£ç¡®? (yes/no): "
  read confirm
  if [ "$confirm" != "yes" ]; then
    print_error "éƒ¨ç½²å·²å–æ¶ˆ"
    exit 1
  fi

  # é€‰æ‹©èµ·å§‹æ­¥éª¤
  echo -e "\n${YELLOW}=== é€‰æ‹©æ“ä½œæ¨¡å¼ ===${NC}"
  echo -e "  ${GREEN}éƒ¨ç½²ç›¸å…³:${NC}"
  echo "    1) ä»å¤´å¼€å§‹å®Œæ•´éƒ¨ç½²"
  echo "    2) æ£€æŸ¥èŠ‚ç‚¹è¿æ¥æ€§"
  echo "    3) é…ç½®èŠ‚ç‚¹åŸºç¡€ç¯å¢ƒ"
  echo "    4) é…ç½®hostsæ–‡ä»¶"
  echo "    5) é…ç½®SSHæ— å¯†ç ç™»å½•"
  echo "    6) å®‰è£…Hadoop"
  echo "    7) é…ç½®Hadoopé›†ç¾¤æ–‡ä»¶"
  echo "    8) åˆ†å‘Hadoopåˆ°SlaveèŠ‚ç‚¹"
  echo "    9) å¯åŠ¨é›†ç¾¤"
  echo "    10) éªŒè¯é›†ç¾¤çŠ¶æ€"
  echo "    11) åœæ­¢é›†ç¾¤"
  echo "    12) æ¸…ç†å¹¶é‡ç½®ç¯å¢ƒå˜é‡"
  echo "    0) é€€å‡ºè„šæœ¬"
  echo ""
  echo -n "è¯·é€‰æ‹©æ“ä½œ [0-12] (é»˜è®¤1): "
  read step_choice
  START_STEP=${step_choice:-1}

  if [ "$START_STEP" -eq 0 ]; then
    print_info "ç”¨æˆ·é€‰æ‹©é€€å‡º"
    exit 0
  fi

  if [ "$START_STEP" -eq 11 ]; then
    stop_cluster
    exit 0
  fi

  if [ "$START_STEP" -eq 12 ]; then
    reset_environment_variables
    exit 0
  fi

  if [ "$START_STEP" -lt 1 ] || [ "$START_STEP" -gt 12 ]; then
    print_error "æ— æ•ˆçš„é€‰æ‹©"
    exit 1
  fi

  print_success "å°†ä»æ­¥éª¤ $START_STEP å¼€å§‹æ‰§è¡Œ"
}

#=============================================================================
# æ£€æŸ¥èŠ‚ç‚¹è¿æ¥æ€§
#=============================================================================

check_node_connectivity() {
  if [ "$START_STEP" -gt 2 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 2: æ£€æŸ¥èŠ‚ç‚¹è¿æ¥æ€§"
    return 0
  fi

  print_step "æ­¥éª¤ 2: æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹è¿æ¥æ€§"

  local total_nodes=$((SLAVE_COUNT + 1))
  local current=0

  # æ£€æŸ¥Master
  current=$((current + 1))
  show_progress $current $total_nodes "æ£€æŸ¥ Master èŠ‚ç‚¹ ($MASTER_IP)"
  if sshpass -p "$CURRENT_USER_PASSWORD" ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 ${CURRENT_USER}@${MASTER_IP} "echo ok" &>/dev/null; then
    echo ""
    print_success "Master èŠ‚ç‚¹è¿æ¥æ­£å¸¸"
  else
    echo ""
    print_error "æ— æ³•è¿æ¥åˆ° Master èŠ‚ç‚¹ $MASTER_IP"
    exit 1
  fi

  # æ£€æŸ¥æ‰€æœ‰Slave
  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    current=$((current + 1))
    show_progress $current $total_nodes "æ£€æŸ¥ Slave èŠ‚ç‚¹ ${SLAVE_HOSTNAMES[$i]} (${SLAVE_IPS[$i]})"
    if sshpass -p "$CURRENT_USER_PASSWORD" ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 ${CURRENT_USER}@${SLAVE_IPS[$i]} "echo ok" &>/dev/null; then
      echo ""
      print_success "${SLAVE_HOSTNAMES[$i]} èŠ‚ç‚¹è¿æ¥æ­£å¸¸"
    else
      echo ""
      print_error "æ— æ³•è¿æ¥åˆ° Slave èŠ‚ç‚¹ ${SLAVE_IPS[$i]}"
      exit 1
    fi
  done

  echo ""
  print_success "æ‰€æœ‰èŠ‚ç‚¹è¿æ¥æ£€æŸ¥å®Œæˆ"
}

#=============================================================================
# é…ç½®å•ä¸ªèŠ‚ç‚¹
#=============================================================================

configure_single_node() {
  local node_ip=$1
  local hostname=$2
  local is_master=$3
  local node_label="[$hostname]"

  print_info "$node_label å¼€å§‹åŸºç¡€é…ç½®"

  # =====================================================
  # 1. æ£€æŸ¥å¹¶åˆ›å»º hadoop ç”¨æˆ·
  # =====================================================
  print_progress "$node_label æ£€æŸ¥ hadoop ç”¨æˆ·..."

  local user_exists=$(sshpass -p "$CURRENT_USER_PASSWORD" ssh -o StrictHostKeyChecking=no ${CURRENT_USER}@${node_ip} \
    "id '$HADOOP_USER' &>/dev/null && echo 'yes' || echo 'no'")

  if [[ "$user_exists" == "yes" ]]; then
    print_success "$node_label hadoop ç”¨æˆ·å·²å­˜åœ¨"

    ask_user_choice "$node_label hadoop ç”¨æˆ·å·²å­˜åœ¨ï¼Œæ˜¯å¦é‡æ–°é…ç½®?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "reinstall")
      print_info "$node_label é‡æ–°é…ç½® hadoop ç”¨æˆ·"
      exec_remote "$node_ip" "sudo userdel -r $HADOOP_USER 2>/dev/null || true" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
      exec_remote "$node_ip" "sudo useradd -m -s /bin/bash '$HADOOP_USER' && echo '$HADOOP_USER:$HADOOP_PASSWORD' | sudo chpasswd && sudo usermod -aG sudo '$HADOOP_USER'" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
      ;;
    "skip")
      print_info "$node_label è·³è¿‡ hadoop ç”¨æˆ·é…ç½®"
      ;;
    esac
  else
    print_info "$node_label åˆ›å»º hadoop ç”¨æˆ·"
    exec_remote "$node_ip" "sudo useradd -m -s /bin/bash '$HADOOP_USER'" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    exec_remote "$node_ip" "echo '$HADOOP_USER:$HADOOP_PASSWORD' | sudo chpasswd" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    exec_remote "$node_ip" "sudo usermod -aG sudo '$HADOOP_USER'" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    print_success "$node_label hadoop ç”¨æˆ·åˆ›å»ºå®Œæˆ"
  fi

  # =====================================================
  # 2. è®¾ç½®ä¸»æœºå
  # =====================================================
  print_progress "$node_label æ£€æŸ¥ä¸»æœºå..."

  local current_hostname=$(sshpass -p "$CURRENT_USER_PASSWORD" ssh -o StrictHostKeyChecking=no ${CURRENT_USER}@${node_ip} "hostname")

  if [[ "$current_hostname" != "$hostname" ]]; then
    print_info "$node_label æ›´æ–°ä¸»æœºå: $current_hostname -> $hostname"
    exec_remote "$node_ip" "sudo hostnamectl set-hostname '$hostname'" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    print_success "$node_label ä¸»æœºåæ›´æ–°å®Œæˆ"
  else
    print_success "$node_label ä¸»æœºåå·²æ­£ç¡®: $hostname"
  fi

  # =====================================================
  # 3. å®‰è£…åŸºç¡€è½¯ä»¶
  # =====================================================
  print_progress "$node_label æ£€æŸ¥å¿…è¦è½¯ä»¶..."

  local missing_packages=""
  for pkg in wget ssh sshpass vim net-tools rsync; do
    local installed=$(sshpass -p "$CURRENT_USER_PASSWORD" ssh -o StrictHostKeyChecking=no ${CURRENT_USER}@${node_ip} \
      "dpkg -l | grep -w $pkg &>/dev/null && echo 'yes' || echo 'no'")
    if [[ "$installed" != "yes" ]]; then
      missing_packages="$missing_packages $pkg"
    fi
  done

  if [[ -n "$missing_packages" ]]; then
    print_info "$node_label å®‰è£…ç¼ºå¤±çš„è½¯ä»¶åŒ…:$missing_packages"
    exec_remote "$node_ip" "sudo apt-get update -y" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    exec_remote "$node_ip" "sudo apt-get install -y $missing_packages" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    print_success "$node_label è½¯ä»¶åŒ…å®‰è£…å®Œæˆ"
  else
    print_success "$node_label æ‰€æœ‰å¿…è¦è½¯ä»¶å·²å®‰è£…"
  fi

  # =====================================================
  # 4. å¯åŠ¨ SSH æœåŠ¡
  # =====================================================
  print_progress "$node_label é…ç½® SSH æœåŠ¡..."
  exec_remote "$node_ip" "sudo systemctl enable ssh && sudo systemctl restart ssh" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
  print_success "$node_label SSH æœåŠ¡å·²å¯åŠ¨"

  # =====================================================
  # 5. æ£€æµ‹ JDK å®‰è£…çŠ¶æ€
  # =====================================================
  print_progress "$node_label æ£€æŸ¥ JDK å®‰è£…çŠ¶æ€..."

  local jdk_installed=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${node_ip} \
    "[ -d /usr/lib/jvm/jdk-17.0.12-oracle-x64 ] && java -version 2>&1 | grep -q '17.0.12' && echo 'yes' || echo 'no'")

  if [[ "$jdk_installed" == "yes" ]]; then
    print_success "$node_label JDK 17.0.12 å·²å®‰è£…"

    ask_user_choice "$node_label JDKå·²å®‰è£…ï¼Œæ˜¯å¦é‡æ–°å®‰è£…?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "reinstall")
      print_info "$node_label é‡æ–°å®‰è£… JDK"
      jdk_installed="no"
      ;;
    "skip")
      print_info "$node_label è·³è¿‡ JDK å®‰è£…"
      ;;
    esac
  fi

  # =====================================================
  # 6. å®‰è£… JDK
  # =====================================================
  if [[ "$jdk_installed" == "no" ]]; then
    local dir="$(dirname "$0")"
    local jdk_file="$dir/jdk-17.0.12_linux-x64_bin.deb"

    if [[ ! -f "$jdk_file" ]]; then
      print_error "$node_label æœªæ‰¾åˆ° JDK å®‰è£…åŒ…: $jdk_file"
      print_error "è¯·ä¸‹è½½ jdk-17.0.12_linux-x64_bin.deb å¹¶æ”¾åœ¨è„šæœ¬åŒç›®å½•ä¸‹ï¼Œæˆ–æ‰‹åŠ¨å®‰è£…"
      exit 1
    fi

    print_info "$node_label åˆ†å‘ JDK å®‰è£…åŒ…..."
    sshpass -p "$HADOOP_PASSWORD" rsync -avz --progress -e "ssh -o StrictHostKeyChecking=no" \
      "$jdk_file" ${HADOOP_USER}@${node_ip}:/tmp/ 2>&1 | grep -v "sending incremental" || true

    print_info "$node_label å®‰è£… JDK..."
    exec_remote "$node_ip" "sudo dpkg -i /tmp/jdk-17.0.12_linux-x64_bin.deb" "$HADOOP_USER" "$HADOOP_PASSWORD"

    print_info "$node_label é…ç½® JDK ç¯å¢ƒå˜é‡..."
    exec_remote "$node_ip" "
# æ£€æŸ¥æ˜¯å¦å·²é…ç½®JAVA_HOMEï¼Œé¿å…é‡å¤æ·»åŠ 
if ! grep -q 'JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64' ~/.bashrc; then
    echo '' >> ~/.bashrc
    echo '# Java Environment' >> ~/.bashrc
    echo 'export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64' >> ~/.bashrc
    echo 'export PATH=\\\$PATH:\\\$JAVA_HOME/bin' >> ~/.bashrc
fi
" "$HADOOP_USER" "$HADOOP_PASSWORD"

    print_success "$node_label JDK å®‰è£…å®Œæˆ"
  fi

  # =====================================================
  # 7. æ£€æµ‹ Hadoop å®‰è£…çŠ¶æ€
  # =====================================================
  print_progress "$node_label æ£€æŸ¥ Hadoop å®‰è£…çŠ¶æ€..."

  local hadoop_installed=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${node_ip} \
    "[ -d /usr/local/hadoop ] && [ -f /usr/local/hadoop/bin/hadoop ] && echo 'yes' || echo 'no'")

  if [[ "$hadoop_installed" == "yes" ]]; then
    print_success "$node_label Hadoop å·²å®‰è£…"

    if [[ "$is_master" != "true" ]]; then
      ask_user_choice "$node_label Hadoopå·²å®‰è£…ï¼Œæ˜¯å¦é‡æ–°å®‰è£…?"
      echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
      read -r user_input
      user_input=${user_input:-2}

      case "$user_input" in
      1) choice="reinstall" ;;
      2) choice="skip" ;;
      3) choice="exit" ;;
      *) choice="skip" ;;
      esac

      case "$choice" in
      "exit")
        print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
        exit 0
        ;;
      "reinstall")
        print_info "$node_label å°†åœ¨åç»­æ­¥éª¤é‡æ–°å®‰è£… Hadoop"
        exec_remote "$node_ip" "sudo rm -rf /usr/local/hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD"
        ;;
      "skip")
        print_info "$node_label è·³è¿‡ Hadoop å®‰è£…"
        ;;
      esac
    fi
  else
    print_info "$node_label Hadoop æœªå®‰è£…ï¼Œå°†åœ¨åç»­æ­¥éª¤å®‰è£…"
  fi

  print_success "$node_label èŠ‚ç‚¹åŸºç¡€é…ç½®å®Œæˆ"
}

#=============================================================================
# æ‰€æœ‰èŠ‚ç‚¹çš„åŸºç¡€é…ç½®
#=============================================================================

configure_all_nodes() {
  if [ "$START_STEP" -gt 3 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 3: é…ç½®èŠ‚ç‚¹åŸºç¡€ç¯å¢ƒ"
    return 0
  fi

  print_step "æ­¥éª¤ 3: é…ç½®æ‰€æœ‰èŠ‚ç‚¹çš„åŸºç¡€ç¯å¢ƒ"

  local total_nodes=$((SLAVE_COUNT + 1))
  local current=0

  # é…ç½® Master èŠ‚ç‚¹
  current=$((current + 1))
  show_progress $current $total_nodes "é…ç½® Master èŠ‚ç‚¹"
  echo ""
  configure_single_node "$MASTER_IP" "$MASTER_HOSTNAME" "true"

  # é…ç½®æ‰€æœ‰ Slave èŠ‚ç‚¹
  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    current=$((current + 1))
    show_progress $current $total_nodes "é…ç½® Slave èŠ‚ç‚¹ ${SLAVE_HOSTNAMES[$i]}"
    echo ""
    configure_single_node "${SLAVE_IPS[$i]}" "${SLAVE_HOSTNAMES[$i]}" "false"
  done

  echo ""
  print_success "æ‰€æœ‰èŠ‚ç‚¹åŸºç¡€é…ç½®å®Œæˆ"
}

#=============================================================================
# é…ç½®hostsæ–‡ä»¶
#=============================================================================

configure_hosts_file() {
  if [ "$START_STEP" -gt 4 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 4: é…ç½®hostsæ–‡ä»¶"
    return 0
  fi

  print_step "æ­¥éª¤ 4: é…ç½®æ‰€æœ‰èŠ‚ç‚¹çš„ hosts æ–‡ä»¶"

  # æ£€æŸ¥MasterèŠ‚ç‚¹hostsæ˜¯å¦å·²é…ç½®
  print_progress "æ£€æŸ¥ Master èŠ‚ç‚¹ hosts é…ç½®çŠ¶æ€..."
  local hosts_configured=$(sshpass -p "$CURRENT_USER_PASSWORD" ssh -o StrictHostKeyChecking=no ${CURRENT_USER}@${MASTER_IP} \
    "grep -q '$MASTER_HOSTNAME' /etc/hosts && grep -q '${SLAVE_HOSTNAMES[0]}' /etc/hosts && echo 'yes' || echo 'no'")

  if [[ "$hosts_configured" == "yes" ]]; then
    echo ""
    print_success "æ£€æµ‹åˆ° hosts æ–‡ä»¶å·²é…ç½®"

    ask_user_choice "hostsæ–‡ä»¶å·²é…ç½®ï¼Œæ˜¯å¦é‡æ–°é…ç½®?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "skip")
      print_info "è·³è¿‡ hosts æ–‡ä»¶é…ç½®"
      return 0
      ;;
    esac
  fi

  # ç”Ÿæˆhostså†…å®¹åˆ°ä¸´æ—¶æ–‡ä»¶
  local tmp_hosts="/tmp/hosts_config_$$"
  cat >"$tmp_hosts" <<EOF
127.0.0.1 localhost
$MASTER_IP $MASTER_HOSTNAME
EOF

  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    echo "${SLAVE_IPS[$i]} ${SLAVE_HOSTNAMES[$i]}" >>"$tmp_hosts"
  done

  local total_nodes=$((SLAVE_COUNT + 1))
  local current=0

  # æ›´æ–° Master èŠ‚ç‚¹
  current=$((current + 1))
  show_progress $current $total_nodes "æ›´æ–° Master èŠ‚ç‚¹ hosts"
  sshpass -p "$CURRENT_USER_PASSWORD" scp -o StrictHostKeyChecking=no "$tmp_hosts" ${CURRENT_USER}@${MASTER_IP}:/tmp/hosts_new
  exec_remote "$MASTER_IP" "sudo mv /tmp/hosts_new /etc/hosts && sudo chmod 644 /etc/hosts" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
  echo ""

  # æ›´æ–°æ‰€æœ‰ Slave èŠ‚ç‚¹
  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    current=$((current + 1))
    show_progress $current $total_nodes "æ›´æ–° ${SLAVE_HOSTNAMES[$i]} hosts"
    sshpass -p "$CURRENT_USER_PASSWORD" scp -o StrictHostKeyChecking=no "$tmp_hosts" ${CURRENT_USER}@${SLAVE_IPS[$i]}:/tmp/hosts_new
    exec_remote "${SLAVE_IPS[$i]}" "sudo mv /tmp/hosts_new /etc/hosts && sudo chmod 644 /etc/hosts" "$CURRENT_USER" "$CURRENT_USER_PASSWORD"
    echo ""
  done

  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  rm -f "$tmp_hosts"

  print_success "æ‰€æœ‰èŠ‚ç‚¹ hosts æ–‡ä»¶é…ç½®å®Œæˆ"
}

#=============================================================================
# é…ç½®SSHæ— å¯†ç ç™»å½•
#=============================================================================

configure_ssh_keys() {
  if [ "$START_STEP" -gt 5 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 5: é…ç½®SSHæ— å¯†ç ç™»å½•"
    return 0
  fi

  print_step "æ­¥éª¤ 5: é…ç½® SSH æ— å¯†ç ç™»å½•"

  # æ£€æŸ¥SSHå¯†é’¥æ˜¯å¦å·²é…ç½®
  print_progress "æ£€æŸ¥ Master èŠ‚ç‚¹ SSH å¯†é’¥é…ç½®çŠ¶æ€..."
  local ssh_configured=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
    "[ -f ~/.ssh/id_rsa ] && [ -f ~/.ssh/id_rsa.pub ] && echo 'yes' || echo 'no'")

  if [[ "$ssh_configured" == "yes" ]]; then
    echo ""
    print_success "æ£€æµ‹åˆ° SSH å¯†é’¥å·²å­˜åœ¨"

    ask_user_choice "SSHå¯†é’¥å·²é…ç½®ï¼Œæ˜¯å¦é‡æ–°é…ç½®?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "skip")
      print_info "è·³è¿‡ SSH å¯†é’¥é…ç½®"
      return 0
      ;;
    "reinstall")
      print_info "é‡æ–°é…ç½® SSH å¯†é’¥"
      exec_remote "$MASTER_IP" "rm -rf ~/.ssh/id_rsa*" "$HADOOP_USER" "$HADOOP_PASSWORD"
      ;;
    esac
  fi

  print_info "åœ¨ Master èŠ‚ç‚¹ç”Ÿæˆ SSH å¯†é’¥"
  exec_remote "$MASTER_IP" "mkdir -p ~/.ssh && chmod 700 ~/.ssh" "$HADOOP_USER" "$HADOOP_PASSWORD"
  sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
    "ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa -q"

  print_info "åˆ†å‘ Master å…¬é’¥åˆ°æ‰€æœ‰èŠ‚ç‚¹"
  local count=0
  local total_targets=$((SLAVE_COUNT + 1))

  for node_ip in "$MASTER_IP" "${SLAVE_IPS[@]}"; do
    count=$((count + 1))
    show_progress $count $total_targets "é…ç½® $node_ip æ— å¯†ç ç™»å½•"
    sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
      "sshpass -p '$HADOOP_PASSWORD' ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no ${HADOOP_USER}@${node_ip}" 2>/dev/null
    echo ""
  done

  print_info "é…ç½® SSH å®¢æˆ·ç«¯è®¾ç½®"
  count=0
  for node_ip in "$MASTER_IP" "${SLAVE_IPS[@]}"; do
    count=$((count + 1))
    show_progress $count $total_targets "é…ç½® $node_ip SSHå®¢æˆ·ç«¯"
    exec_remote "$node_ip" "cat > ~/.ssh/config <<EOF
Host *
    StrictHostKeyChecking no
    UserKnownHostsFile=/dev/null
EOF
chmod 600 ~/.ssh/config" "$HADOOP_USER" "$HADOOP_PASSWORD"
    echo ""
  done

  print_success "SSH æ— å¯†ç ç™»å½•é…ç½®å®Œæˆ"
}

#=============================================================================
# å®‰è£… Hadoop
#=============================================================================

install_hadoop() {
  if [ "$START_STEP" -gt 6 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 6: å®‰è£…Hadoop"
    return 0
  fi

  print_step "æ­¥éª¤ 6: åœ¨ Master èŠ‚ç‚¹å®‰è£… Hadoop"

  # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
  print_progress "æ£€æŸ¥ Master èŠ‚ç‚¹ Hadoop å®‰è£…çŠ¶æ€"
  local hadoop_installed=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
    "[ -d /usr/local/hadoop ] && [ -f /usr/local/hadoop/bin/hadoop ] && echo 'yes' || echo 'no'")

  if [[ "$hadoop_installed" == "yes" ]]; then
    echo ""
    ask_user_choice "MasterèŠ‚ç‚¹å·²å®‰è£…Hadoopï¼Œæ˜¯å¦é‡æ–°å®‰è£…?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "reinstall")
      print_info "é‡æ–°å®‰è£… Hadoop"
      exec_remote "$MASTER_IP" "sudo rm -rf /usr/local/hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD"
      ;;
    "skip")
      print_info "è·³è¿‡ Hadoop å®‰è£…ï¼Œä½¿ç”¨ç°æœ‰ç‰ˆæœ¬"
      return 0
      ;;
    esac
  fi

  local dir="$(dirname "$0")"
  local local_pkg="$dir/hadoop-${HADOOP_VERSION}.tar.gz"

  # æ£€æŸ¥æœ¬åœ°å®‰è£…åŒ…
  if [[ -f "$local_pkg" ]]; then
    print_info "æ£€æµ‹åˆ°æœ¬åœ° Hadoop å®‰è£…åŒ…"
    print_info "ä¸Šä¼ æœ¬åœ° Hadoop å®‰è£…åŒ…åˆ° Master èŠ‚ç‚¹"
    sshpass -p "$HADOOP_PASSWORD" rsync -avz --progress -e "ssh -o StrictHostKeyChecking=no" \
      "$local_pkg" ${HADOOP_USER}@${MASTER_IP}:/tmp/ 2>&1 | grep -v "sending incremental" || true
  else
    # æœ¬åœ°æ²¡æœ‰å®‰è£…åŒ…ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦ä¸‹è½½
    echo -n "æœ¬åœ°æœªæ£€æµ‹åˆ° Hadoop å®‰è£…åŒ…ï¼Œæ˜¯å¦ä»é•œåƒæºä¸‹è½½? (y/N): "
    read -r download_online
    if [[ "$download_online" =~ ^[Yy]$ ]]; then
      print_info "ä»é•œåƒæºä¸‹è½½ Hadoop"
      exec_remote "$MASTER_IP" "cd /tmp && wget -q --show-progress https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz || wget -q --show-progress http://mirrors.cloud.aliyuncs.com/apache/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz" "$HADOOP_USER" "$HADOOP_PASSWORD"
    else
      print_warning "ç”¨æˆ·é€‰æ‹©ä¸ä¸‹è½½ Hadoopï¼Œå®‰è£…æµç¨‹ç»ˆæ­¢"
      exit 1
    fi
  fi

  print_info "è§£å‹å¹¶å®‰è£… Hadoop"
  exec_remote "$MASTER_IP" "cd /tmp && tar -zxf hadoop-${HADOOP_VERSION}.tar.gz" "$HADOOP_USER" "$HADOOP_PASSWORD"
  exec_remote "$MASTER_IP" "sudo mv /tmp/hadoop-${HADOOP_VERSION} /usr/local/hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD"
  exec_remote "$MASTER_IP" "sudo chown -R $HADOOP_USER:$HADOOP_USER /usr/local/hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD"

  print_info "é…ç½® Hadoop ç¯å¢ƒå˜é‡"
  exec_remote "$MASTER_IP" "
# æ£€æŸ¥æ˜¯å¦å·²é…ç½®Hadoopç¯å¢ƒå˜é‡ï¼Œé¿å…é‡å¤æ·»åŠ 
if ! grep -q 'HADOOP_HOME=/usr/local/hadoop' ~/.bashrc; then
    echo '' >> ~/.bashrc
    echo '# Hadoop Environment' >> ~/.bashrc
    echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
    echo 'export HADOOP_CONF_DIR=\$HADOOP_HOME/etc/hadoop' >> ~/.bashrc
    echo 'export PATH=\\\$PATH:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin' >> ~/.bashrc
fi
" "$HADOOP_USER" "$HADOOP_PASSWORD"

  print_success "Hadoop å®‰è£…å®Œæˆ"
}

#=============================================================================
# é…ç½®Hadoopé›†ç¾¤æ–‡ä»¶
#=============================================================================

configure_hadoop_files() {
  if [ "$START_STEP" -gt 7 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 7: é…ç½®Hadoopé›†ç¾¤æ–‡ä»¶"
    return 0
  fi

  print_step "æ­¥éª¤ 7: é…ç½® Hadoop é›†ç¾¤æ–‡ä»¶"

  # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å·²ä¿®æ”¹
  print_progress "æ£€æŸ¥ Hadoop é…ç½®æ–‡ä»¶çŠ¶æ€..."
  local config_exists=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
    "grep -q 'hdfs://${MASTER_HOSTNAME}:9000' /usr/local/hadoop/etc/hadoop/core-site.xml 2>/dev/null && echo 'yes' || echo 'no'")

  if [[ "$config_exists" == "yes" ]]; then
    echo ""
    print_success "æ£€æµ‹åˆ° Hadoop é…ç½®æ–‡ä»¶å·²å­˜åœ¨"

    ask_user_choice "Hadoopé…ç½®æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ˜¯å¦é‡æ–°é…ç½®?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "skip")
      print_info "è·³è¿‡ Hadoop é…ç½®æ–‡ä»¶"
      return 0
      ;;
    esac
  fi

  print_progress "é…ç½® hadoop-env.sh"
  exec_remote "$MASTER_IP" "
grep -q 'export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64' /usr/local/hadoop/etc/hadoop/hadoop-env.sh || \
echo 'export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64' | sudo tee -a /usr/local/hadoop/etc/hadoop/hadoop-env.sh
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  print_progress "é…ç½® workers æ–‡ä»¶"
  local workers_content=""
  for hostname in "${SLAVE_HOSTNAMES[@]}"; do
    workers_content+="$hostname"$'\n'
  done

  # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
  local tmp_workers="/tmp/workers_$"
  echo -n "$workers_content" >"$tmp_workers"

  # ä¸Šä¼ å¹¶æ›¿æ¢
  sshpass -p "$HADOOP_PASSWORD" scp -o StrictHostKeyChecking=no "$tmp_workers" ${HADOOP_USER}@${MASTER_IP}:/tmp/workers_new
  exec_remote "$MASTER_IP" "sudo mv /tmp/workers_new /usr/local/hadoop/etc/hadoop/workers && sudo chown $HADOOP_USER:$HADOOP_USER /usr/local/hadoop/etc/hadoop/workers" "$HADOOP_USER" "$HADOOP_PASSWORD"
  rm -f "$tmp_workers"
  echo ""

  print_progress "é…ç½® core-site.xml"
  exec_remote "$MASTER_IP" "cat > /usr/local/hadoop/etc/hadoop/core-site.xml <<XMLEOF
<?xml version='1.0' encoding='UTF-8'?>
<?xml-stylesheet type='text/xsl' href='configuration.xsl'?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://${MASTER_HOSTNAME}:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/usr/local/hadoop/tmp</value>
    </property>
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>${HADOOP_USER}</value>
    </property>
</configuration>
XMLEOF
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  print_progress "é…ç½® hdfs-site.xml"
  exec_remote "$MASTER_IP" "cat > /usr/local/hadoop/etc/hadoop/hdfs-site.xml <<XMLEOF
<?xml version='1.0' encoding='UTF-8'?>
<?xml-stylesheet type='text/xsl' href='configuration.xsl'?>
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>${SLAVE_COUNT}</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/usr/local/hadoop/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/usr/local/hadoop/tmp/dfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.http-address</name>
        <value>${MASTER_HOSTNAME}:9870</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>${MASTER_HOSTNAME}:9868</value>
    </property>
    <property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
    </property>
</configuration>
XMLEOF
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  print_progress "é…ç½® yarn-site.xml"
  exec_remote "$MASTER_IP" "cat > /usr/local/hadoop/etc/hadoop/yarn-site.xml <<XMLEOF
<?xml version='1.0' encoding='UTF-8'?>
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>${MASTER_HOSTNAME}</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>${MASTER_HOSTNAME}:8088</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>2048</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
</configuration>
XMLEOF
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  print_progress "é…ç½® mapred-site.xml"
  exec_remote "$MASTER_IP" "cat > /usr/local/hadoop/etc/hadoop/mapred-site.xml <<XMLEOF
<?xml version='1.0' encoding='UTF-8'?>
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>${MASTER_HOSTNAME}:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>${MASTER_HOSTNAME}:19888</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
XMLEOF
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  exec_remote "$MASTER_IP" "sudo chown -R $HADOOP_USER:$HADOOP_USER /usr/local/hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD"

  print_success "Hadoop é…ç½®æ–‡ä»¶ç”Ÿæˆå®Œæˆ"
}

#=============================================================================
# åˆ†å‘Hadoopåˆ°æ‰€æœ‰SlaveèŠ‚ç‚¹
#=============================================================================

distribute_hadoop() {
  if [ "$START_STEP" -gt 8 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 8: åˆ†å‘Hadoopåˆ°SlaveèŠ‚ç‚¹"
    return 0
  fi

  print_step "æ­¥éª¤ 8: åˆ†å‘ Hadoop åˆ°æ‰€æœ‰ Slave èŠ‚ç‚¹"

  # æ£€æŸ¥ç¬¬ä¸€ä¸ªSlaveæ˜¯å¦å·²æœ‰Hadoop
  print_progress "æ£€æŸ¥ Slave èŠ‚ç‚¹ Hadoop çŠ¶æ€..."
  local slave_hadoop_exists=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${SLAVE_IPS[0]} \
    "[ -d /usr/local/hadoop ] && [ -f /usr/local/hadoop/bin/hadoop ] && echo 'yes' || echo 'no'")

  if [[ "$slave_hadoop_exists" == "yes" ]]; then
    echo ""
    print_success "æ£€æµ‹åˆ° Slave èŠ‚ç‚¹å·²å®‰è£… Hadoop"

    ask_user_choice "SlaveèŠ‚ç‚¹å·²æœ‰Hadoopï¼Œæ˜¯å¦é‡æ–°åˆ†å‘?"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "skip")
      print_info "è·³è¿‡ Hadoop åˆ†å‘"
      return 0
      ;;
    esac
  fi

  local total_slaves=$SLAVE_COUNT
  local current=0

  # å…ˆåœ¨ Master ä¸Šæ‰“åŒ… Hadoop
  print_info "æ­£åœ¨æ‰“åŒ… Hadoop..."
  exec_remote "$MASTER_IP" "cd /usr/local && sudo tar -czf /tmp/hadoop.tar.gz hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD"
  echo ""

  for i in $(seq 0 $((SLAVE_COUNT - 1))); do
    current=$((current + 1))
    show_progress $current $total_slaves "åˆ†å‘åˆ° ${SLAVE_HOSTNAMES[$i]}"

    # åˆ é™¤ç›®æ ‡èŠ‚ç‚¹å·²æœ‰ Hadoopï¼ˆå¯é€‰ï¼‰
    exec_remote "${SLAVE_IPS[$i]}" "sudo rm -rf /usr/local/hadoop" "$HADOOP_USER" "$HADOOP_PASSWORD" 2>/dev/null || true

    # å¤åˆ¶å‹ç¼©åŒ…
    sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
      "scp -o StrictHostKeyChecking=no /tmp/hadoop.tar.gz ${HADOOP_USER}@${SLAVE_IPS[$i]}:/tmp/" 2>/dev/null

    # è§£å‹åˆ° /usr/local å¹¶è®¾ç½®æƒé™
    exec_remote "${SLAVE_IPS[$i]}" "
        sudo tar -xzf /tmp/hadoop.tar.gz -C /usr/local/
        sudo chown -R $HADOOP_USER:$HADOOP_USER /usr/local/hadoop
        rm -f /tmp/hadoop.tar.gz
    " "$HADOOP_USER" "$HADOOP_PASSWORD"

    # é…ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœå°šæœªé…ç½®ï¼‰
    exec_remote "${SLAVE_IPS[$i]}" "
# æ£€æŸ¥æ˜¯å¦å·²é…ç½®Hadoopç¯å¢ƒå˜é‡ï¼Œé¿å…é‡å¤æ·»åŠ 
if ! grep -q 'HADOOP_HOME=/usr/local/hadoop' ~/.bashrc; then
    echo '' >> ~/.bashrc
    echo '# Hadoop Environment' >> ~/.bashrc
    echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
    echo 'export HADOOP_CONF_DIR=\$HADOOP_HOME/etc/hadoop' >> ~/.bashrc
    echo 'export PATH=\\\$PATH:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin' >> ~/.bashrc
fi
" "$HADOOP_USER" "$HADOOP_PASSWORD"

    exec_remote "${SLAVE_IPS[$i]}" "source ~/.bashrc" "$HADOOP_USER" "$HADOOP_PASSWORD"

    echo ""
  done

  # åˆ é™¤ Master ä¸Šçš„ä¸´æ—¶å‹ç¼©åŒ…
  exec_remote "$MASTER_IP" "sudo rm -f /tmp/hadoop.tar.gz" "$HADOOP_USER" "$HADOOP_PASSWORD"

  print_success "Hadoop åˆ†å‘å®Œæˆ"
}

#=============================================================================
# å¯åŠ¨é›†ç¾¤
#=============================================================================

start_cluster() {
  if [ "$START_STEP" -gt 9 ]; then
    print_warning "è·³è¿‡æ­¥éª¤ 9: å¯åŠ¨é›†ç¾¤"
    return 0
  fi

  print_step "æ­¥éª¤ 9: æ ¼å¼åŒ– NameNode å¹¶å¯åŠ¨é›†ç¾¤"

  # æ£€æŸ¥æ˜¯å¦å·²ç»æ ¼å¼åŒ–
  print_progress "æ£€æŸ¥ NameNode æ˜¯å¦å·²æ ¼å¼åŒ–"
  local namenode_formatted=$(sshpass -p "$HADOOP_PASSWORD" ssh -o StrictHostKeyChecking=no ${HADOOP_USER}@${MASTER_IP} \
    "[ -d /usr/local/hadoop/tmp/dfs/name/current ] && echo 'yes' || echo 'no'")

  if [[ "$namenode_formatted" == "yes" ]]; then
    echo ""
    print_warning "æ£€æµ‹åˆ° NameNode å·²ç»æ ¼å¼åŒ–è¿‡"

    ask_user_choice "NameNodeå·²æ ¼å¼åŒ–ï¼Œæ˜¯å¦é‡æ–°æ ¼å¼åŒ–? (é‡æ–°æ ¼å¼åŒ–ä¼šæ¸…ç©ºHDFSæ•°æ®!)"
    echo -n "è¯·è¾“å…¥é€‰æ‹© [1/2/3] (é»˜è®¤ 2): "
    read -r user_input
    user_input=${user_input:-2}

    case "$user_input" in
    1) choice="reinstall" ;;
    2) choice="skip" ;;
    3) choice="exit" ;;
    *) choice="skip" ;;
    esac

    case "$choice" in
    "exit")
      print_warning "ç”¨æˆ·é€‰æ‹©é€€å‡º"
      exit 0
      ;;
    "reinstall")
      print_info "é‡æ–°æ ¼å¼åŒ– NameNode"
      exec_remote "$MASTER_IP" "rm -rf /usr/local/hadoop/tmp/dfs/name/*" "$HADOOP_USER" "$HADOOP_PASSWORD"
      exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
hdfs namenode -format -force
" "$HADOOP_USER" "$HADOOP_PASSWORD"
      ;;
    "skip")
      print_info "è·³è¿‡æ ¼å¼åŒ–æ­¥éª¤"
      ;;
    esac
  else
    echo ""
    print_info "æ ¼å¼åŒ– NameNode"
    exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
hdfs namenode -format -force
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  fi

  print_info "å¯åŠ¨ HDFS"
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
start-dfs.sh
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  sleep 5

  print_info "å¯åŠ¨ YARN"
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
start-yarn.sh
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  sleep 5

  print_info "å¯åŠ¨ JobHistoryServer"
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
mapred --daemon start historyserver
" "$HADOOP_USER" "$HADOOP_PASSWORD"
  sleep 3

  print_success "é›†ç¾¤å¯åŠ¨å®Œæˆ"
}

#=============================================================================
# éªŒè¯é›†ç¾¤
#=============================================================================

verify_cluster() {
  if [ "$START_STEP" -gt 10 ]; then
    return 0
  fi

  print_step "æ­¥éª¤ 10: éªŒè¯é›†ç¾¤çŠ¶æ€"

  print_info "æ£€æŸ¥ Master èŠ‚ç‚¹è¿›ç¨‹:"
  exec_remote "$MASTER_IP" "jps" "$HADOOP_USER" "$HADOOP_PASSWORD"

  echo ""
  print_info "æ£€æŸ¥ HDFS çŠ¶æ€:"
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
hdfs dfsadmin -report
" "$HADOOP_USER" "$HADOOP_PASSWORD"

  echo ""
  print_info "æ£€æŸ¥ YARN èŠ‚ç‚¹:"
  exec_remote "$MASTER_IP" "
export JAVA_HOME=/usr/lib/jvm/jdk-17.0.12-oracle-x64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=\\\$HADOOP_HOME/etc/hadoop
export PATH=\\\$PATH:\\\$JAVA_HOME/bin:\\\$HADOOP_HOME/bin:\\\$HADOOP_HOME/sbin
yarn node -list
" "$HADOOP_USER" "$HADOOP_PASSWORD"

  echo -e "\n${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
  echo -e "${GREEN}â•‘             é›†ç¾¤éƒ¨ç½²å®Œæˆ!                                  â•‘${NC}"
  echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}\n"

  echo -e "${YELLOW}ğŸ“Š Web è®¿é—®åœ°å€:${NC}"
  echo -e "  ${CYAN}NameNode WebUI:${NC}        http://${MASTER_IP}:9870"
  echo -e "  ${CYAN}ResourceManager WebUI:${NC} http://${MASTER_IP}:8088"
  echo -e "  ${CYAN}JobHistory WebUI:${NC}      http://${MASTER_IP}:19888"
  echo ""

  echo -e "${YELLOW}ğŸ” SSH ç™»å½• Master èŠ‚ç‚¹:${NC}"
  echo -e "  ${CYAN}ssh $HADOOP_USER@$MASTER_IP${NC}"
  echo ""

  echo -e "${YELLOW}ğŸ›‘ åœæ­¢é›†ç¾¤å‘½ä»¤ (åœ¨ Master èŠ‚ç‚¹ä»¥ hadoop ç”¨æˆ·æ‰§è¡Œ):${NC}"
  echo -e "  ${CYAN}mapred --daemon stop historyserver${NC}"
  echo -e "  ${CYAN}stop-yarn.sh${NC}"
  echo -e "  ${CYAN}stop-dfs.sh${NC}"
  echo ""
  echo -e "  ${YELLOW}æˆ–ä½¿ç”¨è„šæœ¬å¿«é€Ÿåœæ­¢:${NC}"
  echo -e "  ${CYAN}bash $(basename "$0") # ç„¶åé€‰æ‹©é€‰é¡¹ 11${NC}"
  echo ""

  echo -e "${YELLOW}ğŸ§ª æµ‹è¯• MapReduce ç¤ºä¾‹:${NC}"
  echo -e "  ${CYAN}hdfs dfs -mkdir -p /user/hadoop/input${NC}"
  echo -e "  ${CYAN}hdfs dfs -put \$HADOOP_HOME/etc/hadoop/*.xml /user/hadoop/input${NC}"
  echo -e "  ${CYAN}hadoop jar \$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar wordcount /user/hadoop/input /user/hadoop/output${NC}"
  echo -e "  ${CYAN}hdfs dfs -cat /user/hadoop/output/part-r-00000${NC}"
  echo ""
}

#=============================================================================
# ä¸»å‡½æ•°
#=============================================================================

main() {
  clear
  echo -e "${GREEN}"
  cat <<"EOF"
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     Hadoop é›†ç¾¤è‡ªåŠ¨éƒ¨ç½²è„šæœ¬                               â•‘
    â•‘     Hadoop 3.4.2 + Ubuntu 24.04 + OracleJDK 17            â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
  echo -e "${NC}"

  print_warning "è¯·ç¡®ä¿æ‰€æœ‰ä¸»æœºéƒ½å®‰è£…å¥½äº†openssh-server"
  print_warning "è¯¥è„šæœ¬åªå…è®¸è™šæ‹Ÿæœºç¯å¢ƒï¼Œå› ä¸ºå¯†ç å°†æ˜æ–‡å­˜å‚¨"
  # æ£€æŸ¥å¿…è¦å·¥å…·
  print_info "æ£€æŸ¥å¿…è¦å·¥å…·..."
  if ! command -v sshpass &>/dev/null; then
    print_info "å®‰è£… sshpass..."
    sudo apt update && sudo apt install -y sshpass
  fi

  if ! command -v rsync &>/dev/null; then
    print_info "å®‰è£… rsync..."
    sudo apt update && sudo apt install -y rsync
  fi

  print_success "å¿…è¦å·¥å…·æ£€æŸ¥å®Œæˆ"

  # æ‰§è¡Œéƒ¨ç½²æµç¨‹
  collect_cluster_info

  # æ ¹æ®START_STEPæ‰§è¡Œç›¸åº”æ­¥éª¤
  check_node_connectivity
  configure_all_nodes
  configure_hosts_file
  configure_ssh_keys
  install_hadoop
  configure_hadoop_files
  distribute_hadoop
  start_cluster
  verify_cluster

  print_success "æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆ!"
}

# æ•è·é”™è¯¯
trap 'print_error "è„šæœ¬æ‰§è¡Œå‡ºé”™ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"; exit 1' ERR

# è¿è¡Œä¸»å‡½æ•°
main "$@"
